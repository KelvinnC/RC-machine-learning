{
 "cells": [
  {
   "cell_type": "code",
   "id": "gpu-setup",
   "metadata": {},
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f'Setup OK. GPU: {gpu_name} ({gpu_mem:.1f} GB)')\n",
    "    print(f'CUDA version: {torch.version.cuda}')\n",
    "    print(f'PyTorch version: {torch.__version__}')\n",
    "    print(f'cuDNN benchmark: enabled')\n",
    "else:\n",
    "    print('Setup OK. No GPU found, using CPU.')\n",
    "\n",
    "print(f'Device: {device}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "section1-md",
   "metadata": {},
   "source": [
    "## Section 1: Loading and Inspecting CSV File"
   ]
  },
  {
   "cell_type": "code",
   "id": "load-csv",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Update these paths for your environment\n",
    "CSV = PATH_TO_CSV\n",
    "IMG = PATH_TO_IMAGES\n",
    "\n",
    "CSV_FILE = os.path.expanduser(CSV)\n",
    "IMG_DIR = os.path.expanduser(IMG)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "inspect-csv",
   "metadata": {},
   "source": [
    "df = pd.read_csv(CSV_FILE)\n",
    "df['image_path'] = df['image_path'].apply(lambda p: \n",
    "    os.path.join(IMG_DIR, os.path.basename(p))\n",
    ")\n",
    "df.head(), df.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "plot-steering",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(df.steering_pulse, bins=50)\n",
    "plt.title(\"Steering Distribution\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "section2-md",
   "metadata": {},
   "source": [
    "## Section 2: Normalize Labels"
   ]
  },
  {
   "cell_type": "code",
   "id": "normalize-labels",
   "metadata": {},
   "source": [
    "Steer_MIN, Steer_MAX = 150, 600\n",
    "Steer_Center = (Steer_MIN + Steer_MAX) / 2\n",
    "TH_REV, TH_STOP, TH_MAX = 205, 307, 410\n",
    "\n",
    "def normalize_throttle(p):\n",
    "    if p == TH_STOP:\n",
    "        return 0.0\n",
    "    elif p > TH_STOP:\n",
    "        return (p - TH_STOP) / (TH_MAX - TH_STOP)\n",
    "    else:\n",
    "        return (p - TH_STOP) / (TH_STOP - TH_REV)\n",
    "\n",
    "df[\"steer_norm\"] = (df.steering_pulse - Steer_Center) / (Steer_MAX - Steer_MIN)\n",
    "df[\"throttle_norm\"] = df.throttle_pulse.apply(normalize_throttle)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "section3-md",
   "metadata": {},
   "source": [
    "## Section 3: Train and Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "id": "train-val-split",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, shuffle=True, random_state=42)\n",
    "print(f'Training samples: {len(train_df)}')\n",
    "print(f'Validation samples: {len(val_df)}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "section4-md",
   "metadata": {},
   "source": [
    "## Section 4: Data Pipeline - PyTorch (Preloaded into RAM)"
   ]
  },
  {
   "cell_type": "code",
   "id": "dataset-class",
   "metadata": {},
   "source": [
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "class DrivingDatasetPreloaded(Dataset):\n",
    "    \"\"\"Dataset that preloads all images into RAM for faster training.\"\"\"\n",
    "    \n",
    "    def __init__(self, df, input_size=(66, 200), augment=False):\n",
    "        self.input_size = input_size  # (H, W)\n",
    "        self.augment = augment\n",
    "        self.images = []\n",
    "        self.steers = []\n",
    "        self.throttles = []\n",
    "        \n",
    "        print(f\"Preloading {len(df)} images into RAM...\")\n",
    "        failed = 0\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Loading\"):\n",
    "            img = cv2.imread(row['image_path'])\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (input_size[1], input_size[0]))  # cv2 uses (W, H)\n",
    "                self.images.append(img)\n",
    "                self.steers.append(float(row['steer_norm']))\n",
    "                self.throttles.append(float(row['throttle_norm']))\n",
    "            else:\n",
    "                failed += 1\n",
    "        \n",
    "        mem_mb = len(self.images) * self.images[0].nbytes / 1e6\n",
    "        print(f\"Loaded {len(self.images)} images ({mem_mb:.1f} MB in RAM)\")\n",
    "        if failed > 0:\n",
    "            print(f\"Warning: {failed} images failed to load\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        steer_val = self.steers[idx]\n",
    "        \n",
    "        if self.augment:\n",
    "            img = img.copy()  # Don't modify the cached image\n",
    "            # Random horizontal flip\n",
    "            if np.random.rand() < 0.5:\n",
    "                img = cv2.flip(img, 1)\n",
    "                steer_val = -steer_val\n",
    "            # Brightness jitter in HSV\n",
    "            img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "            v = img_hsv[:, :, 2].astype(np.float32)\n",
    "            v = np.clip(v * (0.8 + 0.4 * np.random.rand()), 0, 255)\n",
    "            img_hsv[:, :, 2] = v.astype(np.uint8)\n",
    "            img = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR)\n",
    "        \n",
    "        # Normalize to [-1, 1] and convert BGR to RGB\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.astype(np.float32) / 127.5 - 1.0\n",
    "        \n",
    "        # PyTorch expects (C, H, W)\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "        \n",
    "        return (\n",
    "            torch.from_numpy(img),\n",
    "            torch.tensor(steer_val, dtype=torch.float32),\n",
    "            torch.tensor(self.throttles[idx], dtype=torch.float32)\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "instantiate-md",
   "metadata": {},
   "source": [
    "### Instantiate Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "id": "create-dataloaders",
   "metadata": {},
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_dataset = DrivingDatasetPreloaded(train_df, input_size=(66, 200), augment=True)\n",
    "val_dataset = DrivingDatasetPreloaded(val_df, input_size=(66, 200), augment=False)\n",
    "\n",
    "# num_workers=0 is fine since data is already in RAM\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f'Training batches: {len(train_loader)}')\n",
    "print(f'Validation batches: {len(val_loader)}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "section5-md",
   "metadata": {},
   "source": [
    "## Section 5: Define Model (NVIDIA PilotNet Architecture)"
   ]
  },
  {
   "cell_type": "code",
   "id": "model-definition",
   "metadata": {},
   "source": [
    "class PilotNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PilotNet, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 24, kernel_size=5, stride=2)\n",
    "        self.conv2 = nn.Conv2d(24, 36, kernel_size=5, stride=2)\n",
    "        self.conv3 = nn.Conv2d(36, 48, kernel_size=5, stride=2)\n",
    "        self.conv4 = nn.Conv2d(48, 64, kernel_size=3, stride=1)\n",
    "        self.conv5 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 1 * 18, 100)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(100, 50)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "        \n",
    "        # Output heads\n",
    "        self.steering_out = nn.Linear(10, 1)\n",
    "        self.throttle_out = nn.Linear(10, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolutional layers with ReLU\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.relu(self.conv5(x))\n",
    "        \n",
    "        # Flatten and fully connected\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        \n",
    "        # Dual output heads\n",
    "        steering = self.steering_out(x)\n",
    "        throttle = self.throttle_out(x)\n",
    "        \n",
    "        return steering, throttle\n",
    "\n",
    "model = PilotNet().to(device)\n",
    "print(model)\n",
    "print(f'\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "section6-md",
   "metadata": {},
   "source": [
    "## Section 6: Training Loop with Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "id": "gpu-monitor",
   "metadata": {},
   "source": [
    "# GPU monitoring utility\n",
    "import csv\n",
    "import time\n",
    "import subprocess\n",
    "\n",
    "class GPUMonitor:\n",
    "    def __init__(self, path='gpu_batch_log.csv', every_n=10):\n",
    "        self.path = path\n",
    "        self.every_n = every_n\n",
    "        self._f = None\n",
    "        self._w = None\n",
    "        self.batch_count = 0\n",
    "    \n",
    "    def start(self):\n",
    "        self._f = open(self.path, 'w', newline='')\n",
    "        self._w = csv.writer(self._f)\n",
    "        self._w.writerow(['ts', 'epoch', 'batch', 'gpu_util', 'mem_used_mb', 'mem_total_mb'])\n",
    "        self._f.flush()\n",
    "    \n",
    "    def _snapshot(self):\n",
    "        try:\n",
    "            out = subprocess.check_output(\n",
    "                'nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total --format=csv,nounits,noheader',\n",
    "                shell=True\n",
    "            ).decode().strip().splitlines()[0]\n",
    "            util, used, total = [float(x.strip()) for x in out.split(',')]\n",
    "            return util, used, total\n",
    "        except Exception:\n",
    "            return float('nan'), float('nan'), float('nan')\n",
    "    \n",
    "    def log_batch(self, epoch, batch):\n",
    "        self.batch_count += 1\n",
    "        if self.every_n and (self.batch_count % self.every_n) != 0:\n",
    "            return\n",
    "        util, used, total = self._snapshot()\n",
    "        self._w.writerow([time.time(), epoch, batch, util, used, total])\n",
    "        self._f.flush()\n",
    "    \n",
    "    def stop(self):\n",
    "        if self._f:\n",
    "            self._f.close()\n",
    "\n",
    "print('GPUMonitor ready.')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "training-loop",
   "metadata": {},
   "source": [
    "import copy\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "# Training settings\n",
    "EPOCHS = 50\n",
    "STEERING_WEIGHT = 1.0\n",
    "THROTTLE_WEIGHT = 0.5\n",
    "EARLY_STOP_PATIENCE = 5\n",
    "\n",
    "# Tracking\n",
    "history = {\n",
    "    'train_loss': [], 'val_loss': [],\n",
    "    'train_steer_loss': [], 'val_steer_loss': [],\n",
    "    'train_throttle_loss': [], 'val_throttle_loss': [],\n",
    "    'train_steer_mae': [], 'val_steer_mae': [],\n",
    "    'train_throttle_mae': [], 'val_throttle_mae': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_model_state = None\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# GPU monitor\n",
    "gpu_monitor = GPUMonitor(path='gpu_batch_log.csv', every_n=5)\n",
    "gpu_monitor.start()\n",
    "\n",
    "# CSV logger\n",
    "csv_log = open('training.log', 'w', newline='')\n",
    "csv_writer = csv.writer(csv_log)\n",
    "csv_writer.writerow(['epoch', 'train_loss', 'val_loss', 'train_steer_mae', 'val_steer_mae', \n",
    "                     'train_throttle_mae', 'val_throttle_mae', 'lr'])\n",
    "\n",
    "# AMP scaler for mixed precision training\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "print(f'Starting training on {device}...')\n",
    "print(f'Training samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}')\n",
    "print(f'Batch size: {BATCH_SIZE}, Epochs: {EPOCHS}')\n",
    "print(f'Mixed precision (AMP): enabled')\n",
    "print('-' * 80)\n",
    "\n",
    "train_start = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_steer_loss = 0.0\n",
    "    train_throttle_loss = 0.0\n",
    "    train_steer_mae = 0.0\n",
    "    train_throttle_mae = 0.0\n",
    "    \n",
    "    for batch_idx, (images, steers, throttles) in enumerate(train_loader):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        steers = steers.to(device, non_blocking=True).unsqueeze(1)\n",
    "        throttles = throttles.to(device, non_blocking=True).unsqueeze(1)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        # Mixed precision forward pass\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            pred_steer, pred_throttle = model(images)\n",
    "            steer_loss = criterion(pred_steer, steers)\n",
    "            throttle_loss = criterion(pred_throttle, throttles)\n",
    "            loss = STEERING_WEIGHT * steer_loss + THROTTLE_WEIGHT * throttle_loss\n",
    "        \n",
    "        # Scaled backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_steer_loss += steer_loss.item()\n",
    "        train_throttle_loss += throttle_loss.item()\n",
    "        train_steer_mae += torch.mean(torch.abs(pred_steer - steers)).item()\n",
    "        train_throttle_mae += torch.mean(torch.abs(pred_throttle - throttles)).item()\n",
    "        \n",
    "        gpu_monitor.log_batch(epoch, batch_idx)\n",
    "    \n",
    "    n_train = len(train_loader)\n",
    "    train_loss /= n_train\n",
    "    train_steer_loss /= n_train\n",
    "    train_throttle_loss /= n_train\n",
    "    train_steer_mae /= n_train\n",
    "    train_throttle_mae /= n_train\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_steer_loss = 0.0\n",
    "    val_throttle_loss = 0.0\n",
    "    val_steer_mae = 0.0\n",
    "    val_throttle_mae = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, steers, throttles in val_loader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            steers = steers.to(device, non_blocking=True).unsqueeze(1)\n",
    "            throttles = throttles.to(device, non_blocking=True).unsqueeze(1)\n",
    "            \n",
    "            with torch.amp.autocast('cuda'):\n",
    "                pred_steer, pred_throttle = model(images)\n",
    "                steer_loss = criterion(pred_steer, steers)\n",
    "                throttle_loss = criterion(pred_throttle, throttles)\n",
    "                loss = STEERING_WEIGHT * steer_loss + THROTTLE_WEIGHT * throttle_loss\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_steer_loss += steer_loss.item()\n",
    "            val_throttle_loss += throttle_loss.item()\n",
    "            val_steer_mae += torch.mean(torch.abs(pred_steer - steers)).item()\n",
    "            val_throttle_mae += torch.mean(torch.abs(pred_throttle - throttles)).item()\n",
    "    \n",
    "    n_val = len(val_loader)\n",
    "    val_loss /= n_val\n",
    "    val_steer_loss /= n_val\n",
    "    val_throttle_loss /= n_val\n",
    "    val_steer_mae /= n_val\n",
    "    val_throttle_mae /= n_val\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Record history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_steer_loss'].append(train_steer_loss)\n",
    "    history['val_steer_loss'].append(val_steer_loss)\n",
    "    history['train_throttle_loss'].append(train_throttle_loss)\n",
    "    history['val_throttle_loss'].append(val_throttle_loss)\n",
    "    history['train_steer_mae'].append(train_steer_mae)\n",
    "    history['val_steer_mae'].append(val_steer_mae)\n",
    "    history['train_throttle_mae'].append(train_throttle_mae)\n",
    "    history['val_throttle_mae'].append(val_throttle_mae)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    csv_writer.writerow([epoch+1, train_loss, val_loss, train_steer_mae, val_steer_mae,\n",
    "                         train_throttle_mae, val_throttle_mae, current_lr])\n",
    "    csv_log.flush()\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    \n",
    "    # epoch summary\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS} ({epoch_time:.1f}s) - '\n",
    "          f'loss: {train_loss:.4f} - steer_mae: {train_steer_mae:.4f} - throttle_mae: {train_throttle_mae:.4f} - '\n",
    "          f'val_loss: {val_loss:.4f} - val_steer_mae: {val_steer_mae:.4f} - val_throttle_mae: {val_throttle_mae:.4f} - '\n",
    "          f'lr: {current_lr:.6f}')\n",
    "    \n",
    "    # Model checkpoint\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_state, 'best.pt')\n",
    "        print(f'  -> Saved best model (val_loss: {val_loss:.6f})')\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "    \n",
    "    if epochs_no_improve >= EARLY_STOP_PATIENCE:\n",
    "        print(f'Early stopping triggered after {epoch+1} epochs')\n",
    "        break\n",
    "\n",
    "# Restore best model\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print('Restored best model weights')\n",
    "\n",
    "total_time = time.time() - train_start\n",
    "gpu_monitor.stop()\n",
    "csv_log.close()\n",
    "print(f'Training complete! Total time: {total_time:.1f}s')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "section7-md",
   "metadata": {},
   "source": [
    "## Section 7: Evaluate and Visualize"
   ]
  },
  {
   "cell_type": "code",
   "id": "plot-loss",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Total Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['lr'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Learning Rate Schedule')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "test-predictions",
   "metadata": {},
   "source": [
    "# Get a batch from validation set and compare predictions\n",
    "model.eval()\n",
    "images, steers_gt, throttles_gt = next(iter(val_loader))\n",
    "images = images.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_steer, pred_throttle = model(images)\n",
    "\n",
    "print('Ground Truth Steering:', steers_gt[:5].numpy())\n",
    "print('Predicted Steering:   ', pred_steer[:5].cpu().numpy().flatten())\n",
    "print()\n",
    "print('Ground Truth Throttle:', throttles_gt[:5].numpy())\n",
    "print('Predicted Throttle:   ', pred_throttle[:5].cpu().numpy().flatten())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "deployment-md",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "id": "save-model",
   "metadata": {},
   "source": [
    "torch.save(model.state_dict(), 'Jan26_pt.pt')\n",
    "print('Saved PyTorch model')\n",
    "\n",
    "model.eval()\n",
    "dummy_input = torch.randn(1, 3, 66, 200).to(device)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    '_pt.onnx',\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['steering', 'throttle'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},\n",
    "        'steering': {0: 'batch_size'},\n",
    "        'throttle': {0: 'batch_size'}\n",
    "    }\n",
    ")\n",
    "print('Exported ONNX model')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "verify-onnx",
   "metadata": {},
   "source": [
    "try:\n",
    "    import onnx\n",
    "    import onnxruntime as ort\n",
    "    \n",
    "    onnx_model = onnx.load('_pt.onnx')\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    print('ONNX model is valid!')\n",
    "    \n",
    "    ort_session = ort.InferenceSession('_pt.onnx')\n",
    "    test_input = np.random.randn(1, 3, 66, 200).astype(np.float32)\n",
    "    outputs = ort_session.run(None, {'input': test_input})\n",
    "    print(f'ONNX inference test - Steering: {outputs[0][0]}, Throttle: {outputs[1][0]}')\n",
    "except ImportError:\n",
    "    print('Install onnx and onnxruntime to verify ONNX model: pip install onnx onnxruntime')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d525c2a7-6d03-4fe3-ac8f-68208ec4e534",
   "metadata": {},
   "source": [
    "## CLEAR RAM"
   ]
  },
  {
   "cell_type": "code",
   "id": "2335b8bb-ab39-4c6c-a9b7-e7ae5f5df430",
   "metadata": {},
   "source": [
    "del train_dataset, val_dataset, train_loader, val_loader\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0b0968d3-437e-43c9-b304-426fdca02f7f",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
